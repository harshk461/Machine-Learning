{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Score\n",
    "The F1 score is the harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0.\n",
    "\n",
    "\n",
    "Why harmonic mean? Since the harmonic mean of a list of numbers skews strongly toward the least elements of the list, it tends (compared to the arithmetic mean) to mitigate the impact of large outliers and aggravate the impact of small ones.\n",
    "\n",
    "An F1 score punishes extreme values more. Ideally, an F1 Score could be an effective evaluation metric in the following classification scenarios:\n",
    "\n",
    "When FP and FN are equally costly — meaning they miss on true positives or find false positives — both impact the model almost the same way, as in our cancer detection classification example\n",
    "Adding more data doesn’t effectively change the outcome effectively\n",
    "TN is high (like with flood predictions, cancer predictions, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.701493\n",
      "Recall: 0.552941\n",
      "F1 score: 0.618421\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_recall_fscore_support as score, precision_score, recall_score, f1_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "dataframe = pandas.read_csv(url)\n",
    "dat = dataframe.values\n",
    "X = dat[:,:-1]\n",
    "y = dat[:,-1]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "\n",
    "model = LogisticRegression()\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "model.fit(X_train, y_train)\n",
    "pred=model.predict(X_test)\n",
    "precision = precision_score(y_test, pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: tp / (tp + fp + fn)\n",
    "f1 = f1_score(y_test, pred)\n",
    "print('F1 score: %f' % f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
